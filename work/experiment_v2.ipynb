{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from DE import DiffentialEvolutionTuner\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from features_engineer import load_data, normalize_data, pca\n",
    "from defines import *\n",
    "import pickle\n",
    "import learner_params as lp\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "learner_objs = {\"cart\": tree.DecisionTreeClassifier(random_state=SEED_CART),\n",
    "                \"rf\": RandomForestClassifier(random_state=SEED_RF),\n",
    "                \"nb\": GaussianNB(),\n",
    "                \"svm\": SVC(random_state=SEED_SVM),\n",
    "                \"knn\": KNeighborsClassifier()\n",
    "                }\n",
    "\n",
    "def pickle_operating(fname, item, flag):\n",
    "    # save or load the pickle file.\n",
    "    file_name = '%s.pickle' % fname\n",
    "    print(file_name)\n",
    "    if flag == 1:\n",
    "        with open(file_name, 'rb') as fs:\n",
    "            item = pickle.load(fs)\n",
    "            return item\n",
    "    else:\n",
    "        with open(file_name, 'wb') as fs:\n",
    "            pickle.dump(item, fs, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_pca_1000.pickle\n",
      "y_train.pickle\n"
     ]
    }
   ],
   "source": [
    "#train_path = './sentences.csv'\n",
    "#X_train, y_train = load_data(train_path, False)\n",
    "#loading features selected file data\n",
    "X_t = pickle_operating('X_pca_1000', None, 1)\n",
    "y_train = pickle_operating('y_train', None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "y = {}\n",
    "#splitting data to train, tune, and test sets\n",
    "X['merged'], X['test'], y['merged'], y['test'] = train_test_split(X_t, y_train, test_size=0.33, random_state=42)\n",
    "X['train'], X['tune'], y['train'], y['tune'] = train_test_split(X['merged'], y['merged'], test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean Length: ', 811)\n"
     ]
    }
   ],
   "source": [
    "import features_engineer as fe\n",
    "#smoting the data\n",
    "balance_klass = fe.SMOTE()\n",
    "l = {0: 2, 1: 3}\n",
    "X['train_smote'], y['train_smote'] = balance_klass.execute(l, samples=X['train'], labels=y['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['train'], y['train'] = reduce_data(y['train'], X['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=SEED_SMOTE)\n",
    "X['train_smote'], y['train_smote'] = sm.fit_sample(X['train'], y['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({'p': 811, 'o': 811, 'n': 811})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(y['train_smote'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['merged_smote'] = np.vstack((X['train_smote'],  X['tune'])) \n",
    "y['merged_smote'] = list(y['train_smote']) + list(y['tune'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_params = lp.param_grid['svm']\n",
    "learner = learner_objs['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to compute untuned score: 19.0482060909 \n",
      "Executing Iteration #1 of DE\n",
      "\n",
      "Running generation 1\n",
      "\n",
      "New member added : {'kernel': 'rbf', 'C': 46, 'coef0': 0.81632653061224492} | Score = 0.828195643239\n",
      "New member added : {'kernel': 'rbf', 'C': 20, 'coef0': 0.15510204081632656} | Score = 0.829017673654\n",
      "New member added : {'kernel': 'rbf', 'C': 38, 'coef0': 0.58673469387755106} | Score = 0.827373612824\n",
      "Best member of population is {'kernel': 'poly', 'C': 14, 'coef0': 0.11836734693877551} | Score = 0.838471023428 with score = 0.838471\n",
      "\n",
      "Running generation 2\n",
      "\n",
      "New member added : {'kernel': 'rbf', 'C': 1, 'coef0': 0.9816326530612246} | Score = 0.848746403617\n",
      "New member added : {'kernel': 'rbf', 'C': 24, 'coef0': 0.57755102040816331} | Score = 0.827373612824\n",
      "Best member of population is {'kernel': 'rbf', 'C': 1, 'coef0': 0.9816326530612246} | Score = 0.848746403617 with score = 0.848746\n",
      "\n",
      "Running generation 3\n",
      "\n",
      "New member added : {'kernel': 'rbf', 'C': 1, 'coef0': 0.36632653061224496} | Score = 0.848746403617\n",
      "New member added : {'kernel': 'rbf', 'C': 9, 'coef0': 0.57755102040816331} | Score = 0.83641594739\n",
      "New member added : {'kernel': 'rbf', 'C': 10, 'coef0': 0.48571428571428577} | Score = 0.836826962598\n",
      "New member added : {'kernel': 'rbf', 'C': 9, 'coef0': 0.58673469387755106} | Score = 0.83641594739\n",
      "Best member of population is {'kernel': 'rbf', 'C': 1, 'coef0': 0.9816326530612246} | Score = 0.848746403617 with score = 0.848746\n",
      "Time taken to tune score: 335.240370989 \n",
      "Untuned Test Score = 0.900751\n",
      "Tuned Test Score = 0.900751\n",
      "Params = {'kernel': 'rbf', 'C': 1, 'coef0': 0.9816326530612246}\n",
      "\n",
      "\n",
      "\n",
      "372.352914095\n"
     ]
    }
   ],
   "source": [
    "# Fetch training, tuning and testing datasets for lucene\n",
    "#X,Y = preprocess(dataset=dataset, do_smote = True)\n",
    "start = timer()\n",
    "de_tuner = DiffentialEvolutionTuner(learner=learner,learner_params=paramgrid,\n",
    "                                    X_train=X['train_smote'], Y_train=y['train_smote'],\n",
    "                                    X_tune=X['tune'], Y_tune=y['tune'],\n",
    "                                    X_merged=X['merged'], Y_merged=y['merged'],\n",
    "                                    X_test=X['test'], Y_test=y['test'],\n",
    "                                    np=10, goal=\"f1\", life=3, cr=0.5, f=0.75)\n",
    "\n",
    "score, best_params, tune_score, untuned_test_score, learner_fit = de_tuner.tune_and_evaluate(1)\n",
    "duration = timer() - start\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#micro\n",
    "from sklearn.model_selection import cross_validate\n",
    "def tuned_learner(model):\n",
    "    if model == 'svm':\n",
    "        clf = SVC(kernel = 'rbf', C = 4, random_state = 1, coef0= 0.306) \n",
    "    elif model == 'rf':\n",
    "        clf = RandomForestClassifier(max_leaf_nodes= 42, min_samples_leaf= 5, n_estimators= 50, max_features= 90, random_state= 1, min_samples_split= 18)\n",
    "    elif model == 'knn':\n",
    "        clf = KNeighborsClassifier(n_neighbors= 8, weights= 'distance')\n",
    "    elif model == 'cart':\n",
    "        clf = tree.DecisionTreeClassifier(max_features= 0.53163265306122454, min_samples_split= 12, random_state= 79, max_depth= 35, min_samples_leaf= 16)\n",
    "    else:\n",
    "        raise NameError('Unknown machine learning model. Please us one of: rf, svm, nb')\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf.pickle\n"
     ]
    }
   ],
   "source": [
    "clf = tuned_learner('rf')\n",
    "#fit and save the model\n",
    "clf.fit(X['train_smote'], y['train_smote'])\n",
    "pickle_operating('rf', clf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run cross-validation on all scores \n",
    "clf = tuned_learner('rf')\n",
    "scores = cross_validate(clf, X_t, y_train, scoring=['precision_micro', 'recall_micro', 'f1_micro', 'f1_macro'],\n",
    "                        cv=5, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score_time': array([ 0.08157611,  0.06754017,  0.07142806,  0.07508707,  0.06344986]), 'fit_time': array([ 28.33412099,  26.621454  ,  27.83389783,  29.41496801,  26.31560493]), 'test_f1_micro': array([ 0.87207703,  0.87826685,  0.87405368,  0.87327824,  0.87250172]), 'test_f1_macro': array([ 0.40883672,  0.46758123,  0.42798562,  0.40989172,  0.39916821]), 'test_recall_micro': array([ 0.87207703,  0.87826685,  0.87405368,  0.87327824,  0.87250172]), 'test_precision_micro': array([ 0.87207703,  0.87826685,  0.87405368,  0.87327824,  0.87250172])}\n"
     ]
    }
   ],
   "source": [
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf4 = SVC(kernel='poly', C= 1, coef0= 1.0, probability=True)\n",
    "clf3 = RandomForestClassifier(max_leaf_nodes= 42, min_samples_leaf= 5, n_estimators= 50, max_features= 90, random_state= 1, min_samples_split= 18)\n",
    "clf1 = tree.DecisionTreeClassifier(max_features= 0.16428571428571431, min_samples_split= 11, random_state= 79, max_depth= 44, min_samples_leaf=10)\n",
    "\n",
    "eclf3 = VotingClassifier(estimators=[\n",
    "       ('cart', clf1), ('knn', clf2), ('rf', clf3), ('svm', clf4)],\n",
    "        voting='soft', weights=[1,2,3,4],\n",
    "        flatten_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(eclf3, X_t, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.3\n",
    "size = int(len(y_train) * split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y_train, test_size=size)\n",
    "start = timer()\n",
    "eclf3.fit(X_train, y_train)\n",
    "duration = timer() - start\n",
    "print(duration)\n",
    "print()\n",
    "print()\n",
    "print(\"Scores on test set: %s\" % classification_report(y_test, eclf3.predict(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
